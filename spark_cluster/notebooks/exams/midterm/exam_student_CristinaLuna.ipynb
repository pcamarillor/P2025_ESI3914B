{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../labs/img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "### <center> **Procesamiento de Datos Masivos** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "**Primer Examen**\n",
    "\n",
    "**Fecha**: 14 de Marzo del 2025\n",
    "\n",
    "**Nombre del estudiante**: Ana Cristina Luna Arellano\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/14 13:42:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkSQL-Exam-1-CristinaLuna  \") \\\n",
    "    .master(\"spark://d9c3cc2bade8:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json, when, avg, desc, year\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType\n",
    "\n",
    "df_employees = spark.read.option(\"header\", \"true\").csv(\"/home/jovyan/notebooks/data/exam_P2025_ESI3914B/employees.csv\")\n",
    "df_departments = spark.read.option(\"header\", \"true\").csv(\"/home/jovyan/notebooks/data/exam_P2025_ESI3914B/departments.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the employee info from the JSON column (20 points):\n",
    "    Extract the following the columns: name (string), department_id (integer), salary (double), and hire_date (date) from the employee_info column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+---------+----------+\n",
      "|name     |department_id|salary   |hire_date |\n",
      "+---------+-------------+---------+----------+\n",
      "|Caitlyn  |103          |115959.78|2002-06-10|\n",
      "|Rachel   |104          |100820.16|2009-07-01|\n",
      "|Carrie   |105          |114421.44|1998-12-10|\n",
      "|Renee    |104          |54688.13 |1995-03-17|\n",
      "|Gabriella|109          |106267.03|1995-02-09|\n",
      "|Kristen  |101          |88237.54 |2010-11-15|\n",
      "|Jonathan |102          |39323.42 |2012-06-30|\n",
      "|Michelle |101          |64262.85 |2005-10-30|\n",
      "|Michelle |105          |103521.88|1991-07-10|\n",
      "|Lisa     |110          |55435.93 |2016-03-25|\n",
      "|Cheryl   |103          |88073.75 |2020-08-21|\n",
      "|Mikayla  |107          |95192.05 |2022-05-13|\n",
      "|Lisa     |104          |36032.49 |2019-05-16|\n",
      "|Sean     |108          |64904.69 |2021-06-06|\n",
      "|Monica   |105          |92589.97 |2022-05-09|\n",
      "|Katelyn  |104          |147225.58|2008-03-14|\n",
      "|Linda    |108          |146632.64|2002-09-04|\n",
      "|Tammy    |109          |128860.4 |2014-04-18|\n",
      "|William  |103          |142645.41|1998-05-25|\n",
      "|Jorge    |109          |87587.51 |2018-03-25|\n",
      "+---------+-------------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"department_id\", IntegerType(), True),\n",
    "    StructField(\"salary\", DoubleType(), True),\n",
    "    StructField(\"hire_date\", DateType(), True)\n",
    "])\n",
    "\n",
    "df_employees = df_employees.withColumn(\"employee_info\", from_json(col(\"employee_info\"), schema))\n",
    "df_employees = df_employees.select(\n",
    "    col(\"employee_info.name\"),\n",
    "    col(\"employee_info.department_id\"),\n",
    "    col(\"employee_info.salary\"),\n",
    "    col(\"employee_info.hire_date\")\n",
    ")\n",
    "\n",
    "df_employees.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Operations (10 points):\n",
    "    Join the employees DataFrame with the departments DataFrame on department_id to enrich the employee data with department details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------+----------+-------------------------------------------+-------------+\n",
      "|department_id|name     |salary   |hire_date |department_name                            |location     |\n",
      "+-------------+---------+---------+----------+-------------------------------------------+-------------+\n",
      "|103          |Caitlyn  |115959.78|2002-06-10|Sales and Marketing                        |Chicago      |\n",
      "|104          |Rachel   |100820.16|2009-07-01|Data Engineering                           |Zapopan      |\n",
      "|105          |Carrie   |114421.44|1998-12-10|Data Science                               |Seattle      |\n",
      "|104          |Renee    |54688.13 |1995-03-17|Data Engineering                           |Zapopan      |\n",
      "|109          |Gabriella|106267.03|1995-02-09|Customer Service                           |San Francisco|\n",
      "|101          |Kristen  |88237.54 |2010-11-15|Human Resources                            |San Diego    |\n",
      "|102          |Jonathan |39323.42 |2012-06-30|Finance and Accounting                     |New York     |\n",
      "|101          |Michelle |64262.85 |2005-10-30|Human Resources                            |San Diego    |\n",
      "|105          |Michelle |103521.88|1991-07-10|Data Science                               |Seattle      |\n",
      "|110          |Lisa     |55435.93 |2016-03-25|Corporate Strategy and Business Development|Los Angeles  |\n",
      "|103          |Cheryl   |88073.75 |2020-08-21|Sales and Marketing                        |Chicago      |\n",
      "|107          |Mikayla  |95192.05 |2022-05-13|Legal                                      |Chicago      |\n",
      "|104          |Lisa     |36032.49 |2019-05-16|Data Engineering                           |Zapopan      |\n",
      "|108          |Sean     |64904.69 |2021-06-06|Research and Development                   |Philadelphia |\n",
      "|105          |Monica   |92589.97 |2022-05-09|Data Science                               |Seattle      |\n",
      "|104          |Katelyn  |147225.58|2008-03-14|Data Engineering                           |Zapopan      |\n",
      "|108          |Linda    |146632.64|2002-09-04|Research and Development                   |Philadelphia |\n",
      "|109          |Tammy    |128860.4 |2014-04-18|Customer Service                           |San Francisco|\n",
      "|103          |William  |142645.41|1998-05-25|Sales and Marketing                        |Chicago      |\n",
      "|109          |Jorge    |87587.51 |2018-03-25|Customer Service                           |San Francisco|\n",
      "+-------------+---------+---------+----------+-------------------------------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_enriched = df_employees.join(df_departments, \"department_id\", \"left\")\n",
    "df_enriched.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations (Using when()) (10 points):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------------+\n",
      "|name     |salary   |salary_category|\n",
      "+---------+---------+---------------+\n",
      "|Caitlyn  |115959.78|High           |\n",
      "|Rachel   |100820.16|High           |\n",
      "|Carrie   |114421.44|High           |\n",
      "|Renee    |54688.13 |Low            |\n",
      "|Gabriella|106267.03|High           |\n",
      "|Kristen  |88237.54 |High           |\n",
      "|Jonathan |39323.42 |Low            |\n",
      "|Michelle |64262.85 |High           |\n",
      "|Michelle |103521.88|High           |\n",
      "|Lisa     |55435.93 |High           |\n",
      "|Cheryl   |88073.75 |High           |\n",
      "|Mikayla  |95192.05 |High           |\n",
      "|Lisa     |36032.49 |Low            |\n",
      "|Sean     |64904.69 |High           |\n",
      "|Monica   |92589.97 |High           |\n",
      "|Katelyn  |147225.58|High           |\n",
      "|Linda    |146632.64|High           |\n",
      "|Tammy    |128860.4 |High           |\n",
      "|William  |142645.41|High           |\n",
      "|Jorge    |87587.51 |High           |\n",
      "+---------+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_enriched = df_enriched.withColumn(\"salary_category\", when(col(\"salary\") >= 55000, \"High\").otherwise(\"Low\"))\n",
    "df_enriched.select(\"name\", \"salary\", \"salary_category\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter and Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------+----------+-------------------------------------------+-------------+---------------+\n",
      "|department_id|name     |salary   |hire_date |department_name                            |location     |salary_category|\n",
      "+-------------+---------+---------+----------+-------------------------------------------+-------------+---------------+\n",
      "|103          |Caitlyn  |115959.78|2002-06-10|Sales and Marketing                        |Chicago      |High           |\n",
      "|104          |Rachel   |100820.16|2009-07-01|Data Engineering                           |Zapopan      |High           |\n",
      "|105          |Carrie   |114421.44|1998-12-10|Data Science                               |Seattle      |High           |\n",
      "|109          |Gabriella|106267.03|1995-02-09|Customer Service                           |San Francisco|High           |\n",
      "|101          |Kristen  |88237.54 |2010-11-15|Human Resources                            |San Diego    |High           |\n",
      "|101          |Michelle |64262.85 |2005-10-30|Human Resources                            |San Diego    |High           |\n",
      "|105          |Michelle |103521.88|1991-07-10|Data Science                               |Seattle      |High           |\n",
      "|110          |Lisa     |55435.93 |2016-03-25|Corporate Strategy and Business Development|Los Angeles  |High           |\n",
      "|103          |Cheryl   |88073.75 |2020-08-21|Sales and Marketing                        |Chicago      |High           |\n",
      "|107          |Mikayla  |95192.05 |2022-05-13|Legal                                      |Chicago      |High           |\n",
      "|108          |Sean     |64904.69 |2021-06-06|Research and Development                   |Philadelphia |High           |\n",
      "|105          |Monica   |92589.97 |2022-05-09|Data Science                               |Seattle      |High           |\n",
      "|104          |Katelyn  |147225.58|2008-03-14|Data Engineering                           |Zapopan      |High           |\n",
      "|108          |Linda    |146632.64|2002-09-04|Research and Development                   |Philadelphia |High           |\n",
      "|109          |Tammy    |128860.4 |2014-04-18|Customer Service                           |San Francisco|High           |\n",
      "|103          |William  |142645.41|1998-05-25|Sales and Marketing                        |Chicago      |High           |\n",
      "|109          |Jorge    |87587.51 |2018-03-25|Customer Service                           |San Francisco|High           |\n",
      "|103          |John     |119796.45|2019-08-18|Sales and Marketing                        |Chicago      |High           |\n",
      "|109          |Thomas   |80599.69 |2021-04-25|Customer Service                           |San Francisco|High           |\n",
      "|103          |Robert   |59194.51 |2010-01-08|Sales and Marketing                        |Chicago      |High           |\n",
      "+-------------+---------+---------+----------+-------------------------------------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+--------+----------+------------------------+-------------+---------------+\n",
      "|department_id|name     |salary  |hire_date |department_name         |location     |salary_category|\n",
      "+-------------+---------+--------+----------+------------------------+-------------+---------------+\n",
      "|104          |Renee    |54688.13|1995-03-17|Data Engineering        |Zapopan      |Low            |\n",
      "|102          |Jonathan |39323.42|2012-06-30|Finance and Accounting  |New York     |Low            |\n",
      "|104          |Lisa     |36032.49|2019-05-16|Data Engineering        |Zapopan      |Low            |\n",
      "|109          |John     |44836.57|2004-11-13|Customer Service        |San Francisco|Low            |\n",
      "|109          |Rachel   |43269.85|1992-07-13|Customer Service        |San Francisco|Low            |\n",
      "|106          |Juan     |39368.32|2018-05-22|Operations              |London       |Low            |\n",
      "|105          |Jorge    |54757.83|2021-11-13|Data Science            |Seattle      |Low            |\n",
      "|103          |Mark     |40930.72|2007-12-19|Sales and Marketing     |Chicago      |Low            |\n",
      "|101          |Andrea   |36776.84|2009-07-05|Human Resources         |San Diego    |Low            |\n",
      "|109          |Ashley   |31316.34|2003-12-12|Customer Service        |San Francisco|Low            |\n",
      "|109          |Luke     |53907.75|1997-10-25|Customer Service        |San Francisco|Low            |\n",
      "|105          |Mikayla  |53675.16|1994-11-14|Data Science            |Seattle      |Low            |\n",
      "|107          |Tonya    |48626.77|2024-10-06|Legal                   |Chicago      |Low            |\n",
      "|103          |Tristan  |52141.69|2023-12-17|Sales and Marketing     |Chicago      |Low            |\n",
      "|105          |Katherine|53978.6 |2010-04-13|Data Science            |Seattle      |Low            |\n",
      "|103          |Renee    |50095.07|2007-01-07|Sales and Marketing     |Chicago      |Low            |\n",
      "|106          |Raymond  |44243.31|2011-08-25|Operations              |London       |Low            |\n",
      "|102          |Juan     |36367.13|2014-09-04|Finance and Accounting  |New York     |Low            |\n",
      "|108          |James    |45984.0 |2011-10-13|Research and Development|Philadelphia |Low            |\n",
      "|108          |Raymond  |31653.09|2002-03-18|Research and Development|Philadelphia |Low            |\n",
      "+-------------+---------+--------+----------+------------------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Filtrar empleados según la categoría de salario\n",
    "df_high_salary = df_enriched.filter(col(\"salary_category\") == \"High\")\n",
    "df_low_salary = df_enriched.filter(col(\"salary_category\") == \"Low\")\n",
    "\n",
    "df_high_salary.show(truncate=False)\n",
    "df_low_salary.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+------------------+\n",
      "|department_name                            |avg_salary        |\n",
      "+-------------------------------------------+------------------+\n",
      "|Corporate Strategy and Business Development|102741.38324414717|\n",
      "|Sales and Marketing                        |100839.65275449108|\n",
      "|Data Engineering                           |101626.29492163012|\n",
      "|Research and Development                   |98714.3003086419  |\n",
      "|Finance and Accounting                     |100731.07877887784|\n",
      "|Customer Service                           |101585.01600000002|\n",
      "|Legal                                      |99366.3129102167  |\n",
      "|Data Science                               |101903.63710344829|\n",
      "|Operations                                 |100169.65621722837|\n",
      "|Human Resources                            |104999.43191489363|\n",
      "+-------------------------------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+------------------+\n",
      "|department_name                            |avg_salary        |\n",
      "+-------------------------------------------+------------------+\n",
      "|Corporate Strategy and Business Development|41590.741833333326|\n",
      "|Sales and Marketing                        |41150.40277777778 |\n",
      "|Data Engineering                           |41358.50794117647 |\n",
      "|Finance and Accounting                     |42740.952888888874|\n",
      "|Research and Development                   |41426.43521126761 |\n",
      "|Customer Service                           |42644.472021276604|\n",
      "|Legal                                      |41160.26616438357 |\n",
      "|Data Science                               |41974.18958333334 |\n",
      "|Operations                                 |40646.100705882345|\n",
      "|Human Resources                            |41751.64784810126 |\n",
      "+-------------------------------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calcular el salario promedio por departamento\n",
    "df_high_avg_salary = df_high_salary.groupBy(\"department_name\").agg(avg(\"salary\").alias(\"avg_salary\"))\n",
    "df_low_avg_salary = df_low_salary.groupBy(\"department_name\").agg(avg(\"salary\").alias(\"avg_salary\"))\n",
    "\n",
    "df_high_avg_salary.show(truncate=False)\n",
    "df_low_avg_salary.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------+----------+-------------------------------------------+-----------+---------------+\n",
      "|department_id|name     |salary   |hire_date |department_name                            |location   |salary_category|\n",
      "+-------------+---------+---------+----------+-------------------------------------------+-----------+---------------+\n",
      "|101          |Gabriella|149989.73|2018-09-14|Human Resources                            |San Diego  |High           |\n",
      "|101          |Katherine|149979.3 |2017-07-26|Human Resources                            |San Diego  |High           |\n",
      "|110          |Ryan     |149963.1 |1990-07-03|Corporate Strategy and Business Development|Los Angeles|High           |\n",
      "|107          |Caitlyn  |149956.54|2000-07-27|Legal                                      |Chicago    |High           |\n",
      "|107          |Mark     |149915.56|2007-11-06|Legal                                      |Chicago    |High           |\n",
      "+-------------+---------+---------+----------+-------------------------------------------+-----------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/14 14:47:12 ERROR TaskSchedulerImpl: Lost executor 0 on 172.21.0.3: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/14 14:49:28 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 26 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "25/03/14 14:49:33 WARN StandaloneSchedulerBackend$StandaloneDriverEndpoint: Ignored task status update (26 state FINISHED) from unknown executor with ID 0\n",
      "[Stage 28:>                                                         (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:>                                                         (0 + 0) / 1]\r"
     ]
    }
   ],
   "source": [
    "# Obtener los Top 5 empleados con salarios más altos\n",
    "df_top5_high = df_high_salary.orderBy(desc(\"salary\")).limit(5)\n",
    "df_top5_low = df_low_salary.orderBy(desc(\"salary\")).limit(5)\n",
    "\n",
    "df_top5_high.show(truncate=False)\n",
    "df_top5_low.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the number of employees whit more years in the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_enriched' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_enriched \u001b[38;5;241m=\u001b[39m \u001b[43mdf_enriched\u001b[49m\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myears_in_company\u001b[39m\u001b[38;5;124m\"\u001b[39m, year(current_date()) \u001b[38;5;241m-\u001b[39m year(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhire_date\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# empleados con más años en la empresa\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df_most_years \u001b[38;5;241m=\u001b[39m df_enriched\u001b[38;5;241m.\u001b[39morderBy(desc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myears_in_company\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_enriched' is not defined"
     ]
    }
   ],
   "source": [
    "df_enriched = df_enriched.withColumn(\"years_in_company\", year(current_date()) - year(col(\"hire_date\")))\n",
    "\n",
    "# empleados con más años en la empresa\n",
    "df_most_years = df_enriched.orderBy(desc(\"years_in_company\"))\n",
    "df_count_most_years = df_most_years.count()\n",
    "\n",
    "df_most_years.show(truncate=False)\n",
    "print(f\"Total empleados con más años en la empresa: {df_count_most_years}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the  Spark Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_salary.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
