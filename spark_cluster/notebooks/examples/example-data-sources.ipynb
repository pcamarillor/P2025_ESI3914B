{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../labs/img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Procesamiento de Datos Masivos** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "### <center> **Ejemplos de Spark SQL: Creando un DataFrame a partir de un dataset de Kaggle** </center>\n",
    "\n",
    "---\n",
    "**Profesor**: Dr. Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creacion de la conexión con el cluster de spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkSQL-PeopleExample\") \\\n",
    "    .master(\"spark://dc612074df78:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------------+\n",
      "|   name|age|        city|\n",
      "+-------+---+------------+\n",
      "|  Alice| 25|    New York|\n",
      "|    Bob| 30| Los Angeles|\n",
      "|Charlie| 35|     Chicago|\n",
      "|  David| 40|     Houston|\n",
      "|    Eve| 22|     Phoenix|\n",
      "|  Frank| 28|Philadelphia|\n",
      "|  Grace| 32| San Antonio|\n",
      "|   Hank| 45|   San Diego|\n",
      "|    Ivy| 29|      Dallas|\n",
      "+-------+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "schema = StructType([StructField(\"name\", StringType(), True),\n",
    "                     StructField(\"age\", StringType(), True),\n",
    "                     StructField(\"city\", StringType(), True)])\n",
    "\n",
    "sample_data = [\n",
    "    (\"Alice\", \"25\", \"New York\"),\n",
    "    (\"Bob\", \"30\", \"Los Angeles\"),\n",
    "    (\"Charlie\", \"35\", \"Chicago\"),\n",
    "    (\"David\", \"40\", \"Houston\"),\n",
    "    (\"Eve\", \"22\", \"Phoenix\"),\n",
    "    (\"Frank\", \"28\", \"Philadelphia\"),\n",
    "    (\"Grace\", \"32\", \"San Antonio\"),\n",
    "    (\"Hank\", \"45\", \"San Diego\"),\n",
    "    (\"Ivy\", \"29\", \"Dallas\")\n",
    "]\n",
    "\n",
    "people_df = spark.createDataFrame(sample_data, schema)\n",
    "people_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls notebooks/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- album_id: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- release_date: timestamp (nullable = true)\n",
      " |-- popularity: integer (nullable = true)\n",
      " |-- danceability: double (nullable = true)\n",
      " |-- energy: double (nullable = true)\n",
      " |-- key: integer (nullable = true)\n",
      " |-- loudness: double (nullable = true)\n",
      " |-- mode: integer (nullable = true)\n",
      " |-- speechiness: double (nullable = true)\n",
      " |-- acousticness: double (nullable = true)\n",
      " |-- instrumentalness: double (nullable = true)\n",
      " |-- liveness: double (nullable = true)\n",
      " |-- valence: double (nullable = true)\n",
      " |-- tempo: double (nullable = true)\n",
      " |-- playlist_id: string (nullable = true)\n",
      " |-- playlist_name: string (nullable = true)\n",
      " |-- duration_mins: double (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tiktok_df = spark.read \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .csv(\"/home/jovyan/notebooks/data/tiktok.csv\")\n",
    "tiktok_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of invocation of `generate_schema()` method from Lab04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Not implemented yet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mteam_name\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspark_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkUtils\n\u001b[0;32m----> 3\u001b[0m \u001b[43mSparkUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/notebooks/lib/team_name/spark_utils.py:6\u001b[0m, in \u001b[0;36mSparkUtils.generate_schema\u001b[0;34m(columns_info)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_schema\u001b[39m(columns_info) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StructType:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot implemented yet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Not implemented yet"
     ]
    }
   ],
   "source": [
    "from team_name.spark_utils import SparkUtils\n",
    "\n",
    "SparkUtils.generate_schema([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SparkContext\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
