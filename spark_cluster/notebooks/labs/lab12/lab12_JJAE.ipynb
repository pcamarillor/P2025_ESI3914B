{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef62190",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Procesamiento de Datos Masivos** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "### <center> **Lab 12: Recommendation System with ALS** </center>\n",
    "\n",
    "---\n",
    "**Profesor**: Dr. Pablo Camarillo Ramirez\n",
    "\n",
    "**Equipo**: JJAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "259ce8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc707dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ALS-Recommendation-JJAE\") \\\n",
    "    .master(\"spark://51f45cfec3c3:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d0ec2a",
   "metadata": {},
   "source": [
    "### Load the movie ratings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85f5d844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     0|      2|   3.0|1424380312|\n",
      "|     0|      3|   1.0|1424380312|\n",
      "|     0|      5|   2.0|1424380312|\n",
      "|     0|      9|   4.0|1424380312|\n",
      "|     0|     11|   1.0|1424380312|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, LongType\n",
    "\n",
    "ratings_schema = StructType([\n",
    "    StructField(\"userId\", IntegerType(), True),\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"rating\", FloatType(), True),\n",
    "    StructField(\"timestamp\", LongType(), True)\n",
    "])\n",
    "\n",
    "ratings_df = spark.read.csv(\n",
    "    \"/home/jovyan/notebooks/data/sample_movielens_ratings.txt\",\n",
    "    sep=\"::\",\n",
    "    schema=ratings_schema\n",
    ")\n",
    "\n",
    "ratings_df.show(5)\n",
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5375cbaf",
   "metadata": {},
   "source": [
    "### Train ALS Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fef63dea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecommendation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ALS\n\u001b[1;32m      3\u001b[0m als \u001b[38;5;241m=\u001b[39m ALS(\n\u001b[1;32m      4\u001b[0m     userCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     itemCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     coldStartStrategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m als\u001b[38;5;241m.\u001b[39mfit(ratings_df)\n",
      "File \u001b[0;32m/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/pyspark/ml/__init__.py:22\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Licensed to the Apache Software Foundation (ASF) under one or more\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# contributor license agreements.  See the NOTICE file distributed with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03mDataFrame-based machine learning APIs to let users quickly assemble and configure practical\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03mmachine learning pipelines.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     Estimator,\n\u001b[1;32m     24\u001b[0m     Model,\n\u001b[1;32m     25\u001b[0m     Predictor,\n\u001b[1;32m     26\u001b[0m     PredictionModel,\n\u001b[1;32m     27\u001b[0m     Transformer,\n\u001b[1;32m     28\u001b[0m     UnaryTransformer,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline, PipelineModel\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     classification,\n\u001b[1;32m     33\u001b[0m     clustering,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     param,\n\u001b[1;32m     45\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/pyspark/ml/base.py:40\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     Any,\n\u001b[1;32m     25\u001b[0m     Callable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     TYPE_CHECKING,\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m since\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m P\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inherit_doc\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparam\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshared\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     43\u001b[0m     HasInputCol,\n\u001b[1;32m     44\u001b[0m     HasOutputCol,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     Params,\n\u001b[1;32m     49\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/pyspark/ml/param/__init__.py:32\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     Any,\n\u001b[1;32m     22\u001b[0m     Callable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     TYPE_CHECKING,\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpy4j\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjava_gateway\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JavaObject\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenseVector, Vector, Matrix\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    maxIter=10,\n",
    "    regParam=0.1,\n",
    "    rank=5,\n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "model = als.fit(ratings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf21c7d",
   "metadata": {},
   "source": [
    "### Generate Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b65724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_recommendations = model.recommendForAllUsers(numItems=5)\n",
    "user_recommendations.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb0aff6",
   "metadata": {},
   "source": [
    "### Evaluate Model with RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf48bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "predictions = model.transform(ratings_df)\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root-mean-square error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45dbcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
